{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f715b37-6d4a-492a-906d-8dad2edb4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.profiler import record_function, profile, ProfilerActivity, schedule\n",
    "from einops import rearrange\n",
    "from lrn_sparseatt.masks import BooleanMask, boolean_mask_to_nested_indices\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0ee44c-340b-4b5f-af3a-4cca396677d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 50\n",
    "\n",
    "@contextmanager\n",
    "def profile_and_report(name):\n",
    "    gc.collect()\n",
    "    sched = schedule(skip_first=10, wait=5, warmup=5, active=N_RUNS - 20)\n",
    "    try:\n",
    "        with profile(activities=[ProfilerActivity.CPU], schedule=sched) as prof:\n",
    "            with record_function(name):\n",
    "                yield prof\n",
    "    finally:\n",
    "        print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=15))\n",
    "        print(f\"Total per run (us): {prof.key_averages().self_cpu_time_total / (N_RUNS-20):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ad3ed-050b-428d-9490-eff693fad5ab",
   "metadata": {},
   "source": [
    "# Initialize scenario\n",
    "\n",
    "First define the sizes of the inputs and of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acef0e80-4320-4322-accc-8832eb7974c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "d_model = 64\n",
    "n_heads = 2\n",
    "head_dim = d_model // n_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2d076-7c25-43dc-87ba-f58d37c1a460",
   "metadata": {},
   "source": [
    "Get an attention mask with some sparsity level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c231c99f-8df8-42cd-bcdf-df4935194572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False,  True, False,  ..., False, False, False],\n",
       "        [False,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False,  True, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False,  True, False]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = BooleanMask.random(seq_len, 0.9).as_tensor(seq_len)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af1ead-3571-4542-9819-a3e766a20628",
   "metadata": {},
   "source": [
    "Initialize random `q, k, v`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69cc1762-c087-4193-91af-990fbdad17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn((n_heads, seq_len, d_model // n_heads))\n",
    "k = torch.randn((n_heads, seq_len, d_model // n_heads))\n",
    "v = torch.randn((n_heads, seq_len, d_model // n_heads))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3ef09-91e1-4c6d-94e1-8522565d1619",
   "metadata": {},
   "source": [
    "# Masked MHSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d47514b4-7e4b-4a16-930a-4f2cb574b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attention(\n",
    "    q: torch.Tensor,\n",
    "    k: torch.Tensor,\n",
    "    v: torch.Tensor,\n",
    "    attn_mask: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    # q, k, v have shape [H, T, D]\n",
    "    # attn_mask has shape [T, T] or [T, T]\n",
    "    head_dim = q.size(2)\n",
    "\n",
    "    attn_weights: torch.Tensor = torch.matmul(q, k.transpose(-2, -1)) / (\n",
    "        head_dim**0.5\n",
    "    )\n",
    "    # attn_weights has shape [H, T, T]\n",
    "\n",
    "    # attn_mask shape should be broadcastable to attn_weights shape\n",
    "    attn_mask = attn_mask.unsqueeze(0)  # shape [1, T, T]\n",
    "    attn_weights = attn_weights.masked_fill(~attn_mask, float(\"-inf\"))\n",
    "    attn_weights = torch.softmax(attn_weights, dim=-1)\n",
    "    return torch.matmul(attn_weights, v)\n",
    "\n",
    "def full_attention(\n",
    "    q: torch.Tensor,\n",
    "    k: torch.Tensor,\n",
    "    v: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    # q, k, v have shape [H, T, D]\n",
    "    # attn_mask has shape [T, T] or [T, T]\n",
    "    head_dim = q.size(2)\n",
    "\n",
    "    attn_weights: torch.Tensor = torch.matmul(q, k.transpose(-2, -1)) / (\n",
    "        head_dim**0.5\n",
    "    )\n",
    "    attn_weights = torch.softmax(attn_weights, dim=-1)\n",
    "    return torch.matmul(attn_weights, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72d1266e-90d2-4698-8c8c-b59ac47338a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "           ProfilerStep*        13.68%     368.746us       100.00%       2.695ms      89.838us            30  \n",
      "       aten::masked_fill         0.91%      24.422us        34.68%     934.542us      31.151us            30  \n",
      "      aten::masked_fill_        28.75%     774.788us        28.75%     774.788us      25.826us            30  \n",
      "            aten::matmul         2.54%      68.544us        24.26%     653.878us      10.898us            60  \n",
      "               aten::bmm        12.72%     342.721us        17.09%     460.582us       7.676us            60  \n",
      "           aten::softmax         0.25%       6.793us        16.87%     454.587us      15.153us            30  \n",
      "          aten::_softmax        16.61%     447.794us        16.61%     447.794us      14.926us            30  \n",
      "               aten::div         6.03%     162.581us         7.33%     197.498us       6.583us            30  \n",
      "             aten::clone         0.37%       9.959us         4.08%     109.917us       3.664us            30  \n",
      "            aten::select         2.91%      78.402us         3.97%     107.036us       0.297us           360  \n",
      "             aten::copy_         3.77%     101.497us         3.77%     101.497us       1.692us            60  \n",
      "            aten::expand         2.18%      58.669us         2.82%      76.000us       0.422us           180  \n",
      "           aten::reshape         1.08%      29.171us         2.44%      65.709us       0.548us           120  \n",
      "        aten::as_strided         2.01%      54.297us         2.01%      54.297us       0.090us           600  \n",
      "       aten::bitwise_not         1.58%      42.544us         1.58%      42.544us       1.418us            30  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.695ms\n",
      "\n",
      "Total per run (us): 89.84\n"
     ]
    }
   ],
   "source": [
    "with profile_and_report(\"dense_attention\") as p:\n",
    "    for _ in range(N_RUNS):\n",
    "        res_dense = compute_attention(q, k, v, mask)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286d13ae-b996-40ff-af17-0a2d1bc6d8b4",
   "metadata": {},
   "source": [
    "# Sparse attention\n",
    "\n",
    "First, lets get the indices of attention weights to compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb5c7168-6722-49b9-b2e9-c25c4fbd2e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NestedTensor(size=(128, j2), offsets=tensor([   0,   12,   24,   36,   48,   60,   72,   84,   96,  108,  120,  132,\n",
       "         144,  156,  168,  180,  192,  204,  216,  228,  240,  252,  264,  276,\n",
       "         288,  300,  312,  324,  336,  348,  360,  372,  384,  396,  408,  420,\n",
       "         432,  444,  456,  468,  480,  492,  504,  516,  528,  540,  552,  564,\n",
       "         576,  588,  600,  612,  624,  636,  648,  660,  672,  684,  696,  708,\n",
       "         720,  732,  744,  756,  768,  780,  792,  804,  816,  828,  840,  852,\n",
       "         864,  876,  888,  900,  912,  924,  936,  948,  960,  972,  984,  996,\n",
       "        1008, 1020, 1032, 1044, 1056, 1068, 1080, 1092, 1104, 1116, 1128, 1140,\n",
       "        1152, 1164, 1176, 1188, 1200, 1212, 1224, 1236, 1248, 1260, 1272, 1284,\n",
       "        1296, 1308, 1320, 1332, 1344, 1356, 1368, 1380, 1392, 1404, 1416, 1428,\n",
       "        1440, 1452, 1464, 1476, 1488, 1500, 1512, 1524, 1536]), contiguous=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = boolean_mask_to_nested_indices(BooleanMask(mask).as_tensor(seq_len))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae021f7f-c816-4892-acd9-0e21bb03010c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.values().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8327d57d-82e9-4640-b98b-8dd3b6055051",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = k.index_select(1, indices.values()).view(n_heads, -1, head_dim)\n",
    "vs = v.index_select(1, indices.values()).view(n_heads, -1, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3feb0563-aada-4315-b909-e20e35de19ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 2, j2, 32])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nested import nested_tensor_from_jagged\n",
    "nk = nested_tensor_from_jagged(ks, indices.offsets(), jagged_dim=2)\n",
    "nv = nested_tensor_from_jagged(vs, indices.offsets(), jagged_dim=2)\n",
    "nv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "164ec08f-ec9b-405f-9222-1ae43d585fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 32])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "feeeab50-af56-4560-8034-15d58d45ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2, j2]) torch.Size([128, 2, j2, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 2, 32])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk = (q.transpose(0, 1).unsqueeze(2) * nk).sum(dim=-1)\n",
    "num = (qk - qk.max()).exp()\n",
    "den = num.sum(dim=-1, keepdims=True)\n",
    "attn_weights = num/den\n",
    "print(attn_weights.shape, nv.shape)\n",
    "(attn_weights.unsqueeze(-1) * nv).sum(dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac0e0e36-c7cd-42cd-88de-69cea6ac8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(q, k, v, indices):\n",
    "    ks = k.index_select(1, indices.values()).view(n_heads, -1, head_dim)\n",
    "    vs = v.index_select(1, indices.values()).view(n_heads, -1, head_dim)\n",
    "    nk = nested_tensor_from_jagged(ks, indices.offsets(), jagged_dim=2)\n",
    "    nv = nested_tensor_from_jagged(vs, indices.offsets(), jagged_dim=2)\n",
    "    qk = (q.transpose(0, 1).unsqueeze(2) * nk).sum(dim=-1)\n",
    "    num = (qk - qk.max()).exp()\n",
    "    den = num.sum(dim=-1, keepdims=True)\n",
    "    attn_weights = num/den\n",
    "    return (attn_weights.unsqueeze(-1) * nv).sum(dim=2).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e9f01266-7792-4841-8eea-742788c30193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                           PythonSubclass        22.35%      29.743ms       180.48%     240.174ms     363.900us           660  \n",
      "                            ProfilerStep*         2.91%       3.872ms       100.00%     133.075ms       4.436ms            30  \n",
      "                                aten::mul         1.43%       1.906ms        66.41%      88.377ms     589.181us           150  \n",
      "         aten::_nested_from_padded_tensor         0.03%      35.297us        66.36%      88.307ms       1.472ms            60  \n",
      "                              aten::copy_        46.01%      61.228ms        46.01%      61.228ms       3.971us         15420  \n",
      "                            aten::flatten         0.12%     165.003us        43.21%      57.501ms     958.356us            60  \n",
      "                              aten::clone         0.05%      72.620us        43.05%      57.289ms     954.815us            60  \n",
      "                                aten::sum         0.80%       1.070ms        19.95%      26.542ms     147.456us           180  \n",
      "                   aten::to_padded_tensor         0.02%      28.039us        15.19%      20.209ms     336.814us            60  \n",
      "    aten::_padded_dense_to_jagged_forward         4.70%       6.258ms        14.08%      18.742ms     312.372us            60  \n",
      "    aten::_jagged_to_padded_dense_forward         4.62%       6.147ms        13.22%      17.589ms     293.142us            60  \n",
      "                                aten::div         0.09%     126.372us         9.83%      13.082ms     145.355us            90  \n",
      "                             aten::select         5.43%       7.228ms         7.29%       9.697ms       0.210us         46140  \n",
      "                              aten::slice         2.98%       3.970ms         4.31%       5.732ms       0.187us         30720  \n",
      "                         aten::as_strided         3.25%       4.319ms         3.25%       4.319ms       0.056us         77340  \n",
      "-----------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 133.075ms\n",
      "\n",
      "Total per run (us): 4435.83\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 8192 / 8192 (100.0%)\nGreatest absolute difference: 3.691958427429199 at index (0, 102, 13) (up to 1e-05 allowed)\nGreatest relative difference: 1476.8680419921875 at index (0, 1, 7) (up to 1.3e-06 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m         out = test(q, k, v, indices)\n\u001b[32m      4\u001b[39m         p.step()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m.\u001b[49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_dense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/learn-spare-attn/.venv/lib/python3.13/site-packages/torch/testing/_comparison.py:1600\u001b[39m, in \u001b[36massert_close\u001b[39m\u001b[34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[39m\n\u001b[32m   1578\u001b[39m error_metas = not_close_error_metas(\n\u001b[32m   1579\u001b[39m     actual,\n\u001b[32m   1580\u001b[39m     expected,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1595\u001b[39m     msg=msg,\n\u001b[32m   1596\u001b[39m )\n\u001b[32m   1598\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[32m   1599\u001b[39m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1600\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[32m0\u001b[39m].to_error(msg)\n",
      "\u001b[31mAssertionError\u001b[39m: Tensor-likes are not close!\n\nMismatched elements: 8192 / 8192 (100.0%)\nGreatest absolute difference: 3.691958427429199 at index (0, 102, 13) (up to 1e-05 allowed)\nGreatest relative difference: 1476.8680419921875 at index (0, 1, 7) (up to 1.3e-06 allowed)"
     ]
    }
   ],
   "source": [
    "with profile_and_report(\"nested\") as p:\n",
    "    for _ in range(N_RUNS):\n",
    "        out = test(q, k, v, indices)\n",
    "        p.step()\n",
    "\n",
    "torch.testing.assert_close(res_dense, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb857b6f-d464-4b37-966b-30e8cdeebf21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
