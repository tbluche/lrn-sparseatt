{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f715b37-6d4a-492a-906d-8dad2edb4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.profiler import record_function, profile, ProfilerActivity, schedule\n",
    "from einops import rearrange\n",
    "from lrn_sparseatt.masks import BooleanMask, boolean_mask_to_jagged_indices\n",
    "from lrn_sparseatt.ops import sparse_matmul, sparse_matmul_vo\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0ee44c-340b-4b5f-af3a-4cca396677d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 50\n",
    "\n",
    "@contextmanager\n",
    "def profile_and_report(name):\n",
    "    gc.collect()\n",
    "    sched = schedule(skip_first=10, wait=5, warmup=5, active=N_RUNS - 20)\n",
    "    try:\n",
    "        with profile(activities=[ProfilerActivity.CPU], schedule=sched) as prof:\n",
    "            with record_function(name):\n",
    "                yield prof\n",
    "    finally:\n",
    "        print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=15))\n",
    "        print(f\"Total per run (us): {prof.key_averages().self_cpu_time_total / (N_RUNS-20):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ad3ed-050b-428d-9490-eff693fad5ab",
   "metadata": {},
   "source": [
    "# Initialize scenario\n",
    "\n",
    "First define the sizes of the inputs and of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acef0e80-4320-4322-accc-8832eb7974c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "d_model = 64\n",
    "n_heads = 1\n",
    "head_dim = d_model // n_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2d076-7c25-43dc-87ba-f58d37c1a460",
   "metadata": {},
   "source": [
    "Get an attention mask with some sparsity level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c231c99f-8df8-42cd-bcdf-df4935194572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True,  ...,  True,  True, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False,  True, False,  ..., False,  True,  True],\n",
       "        [False, False, False,  ..., False,  True, False],\n",
       "        [False, False, False,  ..., False,  True, False]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = BooleanMask.random(seq_len, 0.7).as_tensor(seq_len)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af1ead-3571-4542-9819-a3e766a20628",
   "metadata": {},
   "source": [
    "Initialize random `q, k, v`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69cc1762-c087-4193-91af-990fbdad17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn((n_heads, seq_len, d_model // n_heads))\n",
    "k = torch.randn((n_heads, seq_len, d_model // n_heads))\n",
    "v = torch.randn((n_heads, seq_len, d_model // n_heads))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3ef09-91e1-4c6d-94e1-8522565d1619",
   "metadata": {},
   "source": [
    "# Masked MHSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47514b4-7e4b-4a16-930a-4f2cb574b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attention(\n",
    "    q: torch.Tensor,\n",
    "    k: torch.Tensor,\n",
    "    v: torch.Tensor,\n",
    "    attn_mask: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    # q, k, v have shape [H, T, D]\n",
    "    # attn_mask has shape [T, T] or [T, T]\n",
    "    head_dim = q.size(2)\n",
    "\n",
    "    attn_weights: torch.Tensor = torch.matmul(q, k.transpose(-2, -1)) / (\n",
    "        head_dim**0.5\n",
    "    )\n",
    "    # attn_weights has shape [H, T, T]\n",
    "\n",
    "    # attn_mask shape should be broadcastable to attn_weights shape\n",
    "    attn_mask = attn_mask.unsqueeze(0)  # shape [1, T, T]\n",
    "    attn_weights = attn_weights.masked_fill(~attn_mask, float(\"-inf\"))\n",
    "    attn_weights = torch.softmax(attn_weights, dim=-1)\n",
    "    return torch.matmul(attn_weights, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d1266e-90d2-4698-8c8c-b59ac47338a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "           ProfilerStep*        18.30%     412.687us       100.00%       2.256ms      75.184us            30  \n",
      "       aten::masked_fill         0.83%      18.666us        34.88%     786.668us      26.222us            30  \n",
      "      aten::masked_fill_        30.65%     691.409us        30.65%     691.409us      23.047us            30  \n",
      "            aten::matmul         3.19%      72.047us        22.33%     503.652us       8.394us            60  \n",
      "           aten::softmax         0.51%      11.502us        15.73%     354.850us      11.828us            30  \n",
      "          aten::_softmax        15.22%     343.348us        15.22%     343.348us      11.445us            30  \n",
      "               aten::bmm        10.95%     246.900us        13.59%     306.556us       5.109us            60  \n",
      "               aten::div         3.36%      75.796us         5.19%     117.171us       3.906us            30  \n",
      "             aten::clone         0.47%      10.590us         3.40%      76.593us       2.553us            30  \n",
      "             aten::copy_         3.08%      69.376us         3.08%      69.376us       1.156us            60  \n",
      "           aten::reshape         1.34%      30.300us         2.87%      64.711us       0.539us           120  \n",
      "            aten::select         1.71%      38.671us         2.36%      53.333us       0.296us           180  \n",
      "            aten::expand         1.71%      38.510us         2.26%      50.884us       0.424us           120  \n",
      "                aten::to         0.27%       5.998us         1.83%      41.375us       1.379us            30  \n",
      "        aten::as_strided         1.58%      35.619us         1.58%      35.619us       0.099us           360  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.256ms\n",
      "\n",
      "Total per run (us): 75.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theodorebluche/src/learn-spare-attn/.venv/lib/python3.13/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n"
     ]
    }
   ],
   "source": [
    "with profile_and_report(\"dense_attention\") as p:\n",
    "    for _ in range(N_RUNS):\n",
    "        res_dense = compute_attention(q, k, v, mask)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286d13ae-b996-40ff-af17-0a2d1bc6d8b4",
   "metadata": {},
   "source": [
    "# Sparse attention\n",
    "\n",
    "First, lets get the indices of attention weights to compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5c7168-6722-49b9-b2e9-c25c4fbd2e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   2],\n",
       "        [  0,   3],\n",
       "        [  0,   7],\n",
       "        ...,\n",
       "        [127, 123],\n",
       "        [127, 124],\n",
       "        [127, 126]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = BooleanMask(mask).to_indices()\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b81ea52c-e39e-4fc1-af30-eb5e009306d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         ProfilerStep*        14.04%     324.161us       100.00%       2.309ms      76.971us            30  \n",
      "    aten::index_select        44.79%       1.034ms        45.10%       1.041ms      17.355us            60  \n",
      "             aten::mul        22.32%     515.473us        22.32%     515.473us      17.182us            30  \n",
      "             aten::sum        16.83%     388.585us        17.45%     402.876us      13.429us            30  \n",
      "            aten::view         0.91%      21.006us         0.91%      21.006us       0.350us            60  \n",
      "           aten::fill_         0.50%      11.582us         0.50%      11.582us       0.386us            30  \n",
      "           aten::empty         0.30%       7.042us         0.30%       7.042us       0.117us            60  \n",
      "         aten::flatten         0.19%       4.289us         0.19%       4.289us       0.071us            60  \n",
      "      aten::as_strided         0.12%       2.709us         0.12%       2.709us       0.090us            30  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.309ms\n",
      "\n",
      "Total per run (us): 76.97\n"
     ]
    }
   ],
   "source": [
    "q_indices = indices[:, 0]\n",
    "kv_indices = indices[:, 1]\n",
    "with profile_and_report(\"indsel_qk\") as p:\n",
    "    for _ in range(N_RUNS):\n",
    "        qs_indsel = q.index_select(1, q_indices.flatten()).view(n_heads, -1, head_dim)\n",
    "        ks_indsel = k.index_select(1, kv_indices.flatten()).view(n_heads, -1, head_dim)\n",
    "        attn_weights = (qs_indsel * ks_indsel).sum(dim=-1) #/ (head_dim**0.5)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a7f2644-c790-44be-9c6f-52c1a72a3416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   ProfilerStep*         7.46%     171.589us       100.00%       2.299ms      76.646us            30  \n",
      "    extension_cpp::sparse_matmul        67.30%       1.547ms        91.32%       2.100ms      69.993us            30  \n",
      "                aten::contiguous         0.28%       6.508us        23.77%     546.641us       6.074us            90  \n",
      "                     aten::clone         0.38%       8.624us        23.49%     540.133us      18.004us            30  \n",
      "                     aten::copy_        22.50%     517.305us        22.70%     521.885us      17.396us            30  \n",
      "                   aten::squeeze         1.03%      23.789us         1.22%      28.001us       0.467us            60  \n",
      "                     aten::empty         0.69%      15.787us         0.69%      15.787us       0.175us            90  \n",
      "                aten::empty_like         0.18%       4.127us         0.42%       9.624us       0.321us            30  \n",
      "                aten::as_strided         0.18%       4.212us         0.18%       4.212us       0.070us            60  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.299ms\n",
      "\n",
      "Total per run (us): 76.65\n"
     ]
    }
   ],
   "source": [
    "with profile_and_report(\"cpp\") as p:\n",
    "    for _ in range(N_RUNS):\n",
    "        attn_weights_2 = sparse_matmul(q.squeeze(0), k.squeeze(0), indices) #/ (head_dim**0.5)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5523b39c-859f-4cbc-8d52-e03db119c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(attn_weights, attn_weights_2.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1693fc16-06bb-47be-bf0f-c2e549cee9f5",
   "metadata": {},
   "source": [
    "# Sparse matmul with values and offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "599eb604-14bf-4300-8135-791bd12eb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, offsets = boolean_mask_to_jagged_indices(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdebf210-ddfd-414e-9d99-65a02221fc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                               Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      ProfilerStep*         9.13%     156.958us       100.00%       1.719ms      57.310us            30  \n",
      "    extension_cpp::sparse_matmul_vo        88.74%       1.526ms        89.25%       1.534ms      51.148us            30  \n",
      "                      aten::squeeze         1.37%      23.624us         1.62%      27.920us       0.465us            60  \n",
      "                        aten::empty         0.39%       6.788us         0.39%       6.788us       0.226us            30  \n",
      "                   aten::as_strided         0.25%       4.296us         0.25%       4.296us       0.072us            60  \n",
      "                   aten::contiguous         0.11%       1.877us         0.11%       1.877us       0.031us            60  \n",
      "-----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.719ms\n",
      "\n",
      "Total per run (us): 57.31\n"
     ]
    }
   ],
   "source": [
    "with profile_and_report(\"cpp_2\") as p:\n",
    "    for _ in range(N_RUNS):\n",
    "        attn_weights_3 = sparse_matmul_vo(q.squeeze(0), k.squeeze(0), values, offsets) #/ (head_dim**0.5)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3a4ae4b-1313-428e-ac6a-83dac23b9d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  38,   76,  114,  152,  190,  228,  266,  304,  342,  380,  418,  456,\n",
       "         494,  532,  570,  608,  646,  684,  722,  760,  798,  836,  874,  912,\n",
       "         950,  988, 1026, 1064, 1102, 1140, 1178, 1216, 1254, 1292, 1330, 1368,\n",
       "        1406, 1444, 1482, 1520, 1558, 1596, 1634, 1672, 1710, 1748, 1786, 1824,\n",
       "        1862, 1900, 1938, 1976, 2014, 2052, 2090, 2128, 2166, 2204, 2242, 2280,\n",
       "        2318, 2356, 2394, 2432, 2470, 2508, 2546, 2584, 2622, 2660, 2698, 2736,\n",
       "        2774, 2812, 2850, 2888, 2926, 2964, 3002, 3040, 3078, 3116, 3154, 3192,\n",
       "        3230, 3268, 3306, 3344, 3382, 3420, 3458, 3496, 3534, 3572, 3610, 3648,\n",
       "        3686, 3724, 3762, 3800, 3838, 3876, 3914, 3952, 3990, 4028, 4066, 4104,\n",
       "        4142, 4180, 4218, 4256, 4294, 4332, 4370, 4408, 4446, 4484, 4522, 4560,\n",
       "        4598, 4636, 4674, 4712, 4750, 4788, 4826, 4864])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab4705-4026-4559-9030-8661e0921807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
