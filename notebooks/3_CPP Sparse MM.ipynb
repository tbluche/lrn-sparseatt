{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f715b37-6d4a-492a-906d-8dad2edb4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.profiler import record_function, profile, ProfilerActivity, schedule\n",
    "from einops import rearrange\n",
    "from lrn_sparseatt.masks import BooleanMask\n",
    "from lrn_sparseatt.ops import sparse_matmul\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0ee44c-340b-4b5f-af3a-4cca396677d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 50\n",
    "\n",
    "@contextmanager\n",
    "def profile_and_report(name):\n",
    "    gc.collect()\n",
    "    sched = schedule(skip_first=10, wait=5, warmup=5, active=N_RUNS - 20)\n",
    "    try:\n",
    "        with profile(activities=[ProfilerActivity.CPU], schedule=sched) as prof:\n",
    "            with record_function(name):\n",
    "                yield prof\n",
    "    finally:\n",
    "        print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=15))\n",
    "        print(f\"Total per run (us): {prof.key_averages().self_cpu_time_total / (N_RUNS-20):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ad3ed-050b-428d-9490-eff693fad5ab",
   "metadata": {},
   "source": [
    "# Initialize scenario\n",
    "\n",
    "First define the sizes of the inputs and of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acef0e80-4320-4322-accc-8832eb7974c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "d_model = 64\n",
    "n_heads = 1\n",
    "head_dim = d_model // n_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2d076-7c25-43dc-87ba-f58d37c1a460",
   "metadata": {},
   "source": [
    "Get an attention mask with some sparsity level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c231c99f-8df8-42cd-bcdf-df4935194572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False,  True, False],\n",
       "        [ True,  True, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False,  True,  True],\n",
       "        [ True, False, False,  ...,  True, False, False]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = BooleanMask.random(seq_len, 0.7).as_tensor(seq_len)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af1ead-3571-4542-9819-a3e766a20628",
   "metadata": {},
   "source": [
    "Initialize random `q, k, v`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69cc1762-c087-4193-91af-990fbdad17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn((n_heads, seq_len, d_model // n_heads))\n",
    "k = torch.randn((n_heads, seq_len, d_model // n_heads))\n",
    "v = torch.randn((n_heads, seq_len, d_model // n_heads))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3ef09-91e1-4c6d-94e1-8522565d1619",
   "metadata": {},
   "source": [
    "# Masked MHSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47514b4-7e4b-4a16-930a-4f2cb574b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attention(\n",
    "    q: torch.Tensor,\n",
    "    k: torch.Tensor,\n",
    "    v: torch.Tensor,\n",
    "    attn_mask: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    # q, k, v have shape [H, T, D]\n",
    "    # attn_mask has shape [T, T] or [T, T]\n",
    "    head_dim = q.size(2)\n",
    "\n",
    "    attn_weights: torch.Tensor = torch.matmul(q, k.transpose(-2, -1)) / (\n",
    "        head_dim**0.5\n",
    "    )\n",
    "    # attn_weights has shape [H, T, T]\n",
    "\n",
    "    # attn_mask shape should be broadcastable to attn_weights shape\n",
    "    attn_mask = attn_mask.unsqueeze(0)  # shape [1, T, T]\n",
    "    attn_weights = attn_weights.masked_fill(~attn_mask, float(\"-inf\"))\n",
    "    attn_weights = torch.softmax(attn_weights, dim=-1)\n",
    "    return torch.matmul(attn_weights, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d1266e-90d2-4698-8c8c-b59ac47338a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "           ProfilerStep*        25.74%     775.288us       100.00%       3.012ms     100.388us            30  \n",
      "       aten::masked_fill         4.90%     147.465us        32.21%     970.185us      32.340us            30  \n",
      "      aten::masked_fill_        20.13%     606.369us        20.13%     606.369us      20.212us            30  \n",
      "            aten::matmul         2.66%      80.088us        18.64%     561.454us       9.358us            60  \n",
      "           aten::softmax         4.52%     136.178us        16.16%     486.740us      16.225us            30  \n",
      "          aten::_softmax        11.64%     350.562us        11.64%     350.562us      11.685us            30  \n",
      "               aten::bmm         8.65%     260.598us        11.02%     332.020us       5.534us            60  \n",
      "             aten::clone         4.86%     146.217us         7.18%     216.351us       7.212us            30  \n",
      "               aten::div         2.79%      84.008us         4.26%     128.343us       4.278us            30  \n",
      "           aten::reshape         1.44%      43.388us         2.74%      82.428us       0.687us           120  \n",
      "             aten::copy_         2.42%      72.800us         2.42%      72.800us       1.213us            60  \n",
      "            aten::select         1.60%      48.176us         2.15%      64.884us       0.360us           180  \n",
      "            aten::expand         1.41%      42.372us         1.86%      55.877us       0.466us           120  \n",
      "                aten::to         0.23%       6.790us         1.47%      44.335us       1.478us            30  \n",
      "        aten::as_strided         1.32%      39.672us         1.32%      39.672us       0.110us           360  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.012ms\n",
      "\n",
      "Total per run (us): 100.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theodorebluche/src/learn-spare-attn/.venv/lib/python3.13/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n"
     ]
    }
   ],
   "source": [
    "with profile_and_report(\"dense_attention\") as p:\n",
    "    for _ in range(N_RUNS):\n",
    "        res_dense = compute_attention(q, k, v, mask)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286d13ae-b996-40ff-af17-0a2d1bc6d8b4",
   "metadata": {},
   "source": [
    "# Sparse attention\n",
    "\n",
    "First, lets get the indices of attention weights to compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5c7168-6722-49b9-b2e9-c25c4fbd2e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   6],\n",
       "        [  0,   7],\n",
       "        [  0,  11],\n",
       "        ...,\n",
       "        [127, 114],\n",
       "        [127, 116],\n",
       "        [127, 125]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = BooleanMask(mask).to_indices()\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b81ea52c-e39e-4fc1-af30-eb5e009306d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         ProfilerStep*        16.75%     578.709us       100.00%       3.455ms     115.168us            30  \n",
      "    aten::index_select        35.52%       1.227ms        35.78%       1.236ms      20.601us            60  \n",
      "             aten::mul        28.09%     970.680us        28.09%     970.680us      32.356us            30  \n",
      "             aten::sum        17.81%     615.208us        18.43%     636.879us      21.229us            30  \n",
      "            aten::view         0.81%      27.874us         0.81%      27.874us       0.465us            60  \n",
      "           aten::fill_         0.50%      17.128us         0.50%      17.128us       0.571us            30  \n",
      "           aten::empty         0.26%       9.000us         0.26%       9.000us       0.150us            60  \n",
      "         aten::flatten         0.14%       4.832us         0.14%       4.832us       0.081us            60  \n",
      "      aten::as_strided         0.13%       4.543us         0.13%       4.543us       0.151us            30  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.455ms\n",
      "\n",
      "Total per run (us): 115.17\n"
     ]
    }
   ],
   "source": [
    "q_indices = indices[:, 0]\n",
    "kv_indices = indices[:, 1]\n",
    "with profile_and_report(\"indsel_qk\") as p:\n",
    "    for _ in range(N_RUNS):\n",
    "        qs_indsel = q.index_select(1, q_indices.flatten()).view(n_heads, -1, head_dim)\n",
    "        ks_indsel = k.index_select(1, kv_indices.flatten()).view(n_heads, -1, head_dim)\n",
    "        attn_weights = (qs_indsel * ks_indsel).sum(dim=-1) #/ (head_dim**0.5)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a7f2644-c790-44be-9c6f-52c1a72a3416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   ProfilerStep*         7.55%     162.807us       100.00%       2.156ms      71.853us            30  \n",
      "    extension_cpp::sparse_matmul        66.94%       1.443ms        91.09%       1.963ms      65.448us            30  \n",
      "                aten::contiguous         0.33%       7.074us        23.89%     514.885us       5.721us            90  \n",
      "                     aten::clone         0.42%       9.042us        23.56%     507.811us      16.927us            30  \n",
      "                     aten::copy_        22.52%     485.440us        22.71%     489.439us      16.315us            30  \n",
      "                   aten::squeeze         1.17%      25.251us         1.36%      29.334us       0.489us            60  \n",
      "                     aten::empty         0.66%      14.164us         0.66%      14.164us       0.157us            90  \n",
      "                aten::empty_like         0.22%       4.748us         0.43%       9.330us       0.311us            30  \n",
      "                aten::as_strided         0.19%       4.083us         0.19%       4.083us       0.068us            60  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.156ms\n",
      "\n",
      "Total per run (us): 71.85\n"
     ]
    }
   ],
   "source": [
    "with profile_and_report(\"cpp\") as p:\n",
    "    for _ in range(N_RUNS):\n",
    "        attn_weights_2 = sparse_matmul(q.squeeze(0), k.squeeze(0), indices) #/ (head_dim**0.5)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5523b39c-859f-4cbc-8d52-e03db119c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(attn_weights, attn_weights_2.unsqueeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
