{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f715b37-6d4a-492a-906d-8dad2edb4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.profiler import record_function, profile, ProfilerActivity, schedule\n",
    "from einops import rearrange\n",
    "from lrn_sparseatt.masks import BooleanMask, boolean_mask_to_jagged_indices\n",
    "from lrn_sparseatt.ops import sparse_attn\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0ee44c-340b-4b5f-af3a-4cca396677d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 50\n",
    "\n",
    "@contextmanager\n",
    "def profile_and_report(name):\n",
    "    gc.collect()\n",
    "    sched = schedule(skip_first=10, wait=5, warmup=5, active=N_RUNS - 20)\n",
    "    try:\n",
    "        with profile(activities=[ProfilerActivity.CPU], schedule=sched) as prof:\n",
    "            with record_function(name):\n",
    "                yield prof\n",
    "    finally:\n",
    "        print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=15))\n",
    "        print(f\"Total per run (us): {prof.key_averages().self_cpu_time_total / (N_RUNS-20):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ad3ed-050b-428d-9490-eff693fad5ab",
   "metadata": {},
   "source": [
    "# Initialize scenario\n",
    "\n",
    "First define the sizes of the inputs and of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acef0e80-4320-4322-accc-8832eb7974c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "d_model = 64\n",
    "n_heads = 1\n",
    "head_dim = d_model // n_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2d076-7c25-43dc-87ba-f58d37c1a460",
   "metadata": {},
   "source": [
    "Get an attention mask with some sparsity level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c231c99f-8df8-42cd-bcdf-df4935194572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False,  True,  ..., False, False,  True],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ...,  True, False,  True],\n",
       "        ...,\n",
       "        [ True, False,  True,  ...,  True, False, False],\n",
       "        [False, False,  True,  ..., False, False, False],\n",
       "        [False,  True, False,  ...,  True,  True, False]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = BooleanMask.random(seq_len, 0.7).as_tensor(seq_len)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af1ead-3571-4542-9819-a3e766a20628",
   "metadata": {},
   "source": [
    "Initialize random `q, k, v`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69cc1762-c087-4193-91af-990fbdad17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn((n_heads, seq_len, d_model // n_heads))\n",
    "k = torch.randn((n_heads, seq_len, d_model // n_heads))\n",
    "v = torch.randn((n_heads, seq_len, d_model // n_heads))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3ef09-91e1-4c6d-94e1-8522565d1619",
   "metadata": {},
   "source": [
    "# Masked MHSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47514b4-7e4b-4a16-930a-4f2cb574b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attention(\n",
    "    q: torch.Tensor,\n",
    "    k: torch.Tensor,\n",
    "    v: torch.Tensor,\n",
    "    attn_mask: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    # q, k, v have shape [H, T, D]\n",
    "    # attn_mask has shape [T, T] or [T, T]\n",
    "    head_dim = q.size(2)\n",
    "\n",
    "    attn_weights: torch.Tensor = torch.matmul(q, k.transpose(-2, -1)) / (\n",
    "        head_dim**0.5\n",
    "    )\n",
    "    # attn_weights has shape [H, T, T]\n",
    "\n",
    "    # attn_mask shape should be broadcastable to attn_weights shape\n",
    "    attn_mask = attn_mask.unsqueeze(0)  # shape [1, T, T]\n",
    "    attn_weights = attn_weights.masked_fill(~attn_mask, float(\"-inf\"))\n",
    "    attn_weights = torch.softmax(attn_weights, dim=-1)\n",
    "    return torch.matmul(attn_weights, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d1266e-90d2-4698-8c8c-b59ac47338a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "           ProfilerStep*        18.50%     383.222us       100.00%       2.071ms      69.047us            30  \n",
      "       aten::masked_fill         0.87%      18.004us        33.81%     700.441us      23.348us            30  \n",
      "      aten::masked_fill_        29.28%     606.479us        29.28%     606.479us      20.216us            30  \n",
      "            aten::matmul         3.24%      67.095us        23.87%     494.472us       8.241us            60  \n",
      "           aten::softmax         0.42%       8.625us        14.90%     308.552us      10.285us            30  \n",
      "               aten::bmm        11.85%     245.466us        14.83%     307.217us       5.120us            60  \n",
      "          aten::_softmax        14.48%     299.927us        14.48%     299.927us       9.998us            30  \n",
      "               aten::div         3.54%      73.297us         5.33%     110.341us       3.678us            30  \n",
      "             aten::clone         0.49%      10.120us         3.67%      75.958us       2.532us            30  \n",
      "             aten::copy_         3.29%      68.170us         3.29%      68.170us       1.136us            60  \n",
      "           aten::reshape         1.43%      29.584us         2.96%      61.374us       0.511us           120  \n",
      "            aten::select         1.82%      37.634us         2.68%      55.470us       0.308us           180  \n",
      "            aten::expand         1.88%      38.955us         2.38%      49.246us       0.410us           120  \n",
      "        aten::as_strided         1.79%      37.082us         1.79%      37.082us       0.103us           360  \n",
      "                aten::to         0.26%       5.333us         1.79%      37.044us       1.235us            30  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.071ms\n",
      "\n",
      "Total per run (us): 69.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theodorebluche/src/learn-spare-attn/.venv/lib/python3.13/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n"
     ]
    }
   ],
   "source": [
    "with profile_and_report(\"dense_attention\") as p:\n",
    "    for _ in range(N_RUNS):\n",
    "        res_dense = compute_attention(q, k, v, mask)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286d13ae-b996-40ff-af17-0a2d1bc6d8b4",
   "metadata": {},
   "source": [
    "# Sparse attention\n",
    "\n",
    "First, lets get the indices of attention weights to compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5c7168-6722-49b9-b2e9-c25c4fbd2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = BooleanMask(mask).to_indices()\n",
    "values, offsets = boolean_mask_to_jagged_indices(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1693fc16-06bb-47be-bf0f-c2e549cee9f5",
   "metadata": {},
   "source": [
    "# Sparse matmul with values and offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599eb604-14bf-4300-8135-791bd12eb9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdebf210-ddfd-414e-9d99-65a02221fc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 ProfilerStep*         5.62%     188.126us       100.00%       3.350ms     111.676us            30  \n",
      "    extension_cpp::sparse_attn        91.92%       3.080ms        93.18%       3.122ms     104.055us            30  \n",
      "                 aten::squeeze         1.04%      34.705us         1.21%      40.498us       0.450us            90  \n",
      "               aten::new_zeros         0.28%       9.288us         0.63%      21.205us       0.707us            30  \n",
      "                   aten::empty         0.56%      18.876us         0.56%      18.876us       0.210us            90  \n",
      "                   aten::zero_         0.22%       7.333us         0.22%       7.333us       0.122us            60  \n",
      "               aten::new_empty         0.11%       3.626us         0.21%       6.875us       0.229us            30  \n",
      "              aten::as_strided         0.17%       5.793us         0.17%       5.793us       0.064us            90  \n",
      "              aten::contiguous         0.09%       2.877us         0.09%       2.877us       0.032us            90  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.350ms\n",
      "\n",
      "Total per run (us): 111.68\n"
     ]
    }
   ],
   "source": [
    "with profile_and_report(\"cpp_attn\") as p:\n",
    "    for _ in range(N_RUNS):\n",
    "        res_sparse = sparse_attn(q.squeeze(0), k.squeeze(0), v.squeeze(0), values, offsets, head_dim**0.5)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3a4ae4b-1313-428e-ac6a-83dac23b9d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(res_dense, res_sparse.unsqueeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
